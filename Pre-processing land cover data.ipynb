{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook relies on Python 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processinig land cover data for use in deriving local wind multipliers\n",
    "\n",
    "This notebook demonstrates a quick way to automatically assign a numeric value to (combinations of) land cover categories in a vector shapefile format. It's based on the land cover data available through the [PacGeo repository](http://www.pacgeo.org/), which holds siginficant amounts of geospatial data for Pacific Island nations. \n",
    "\n",
    "We need to assign a numeric value to land cover categories, so we can then convert the data into a raster layer for ingestion into the [wind multiplier code](https://github.com/GeoscienceAustralia/Wind_multipliers), for determination of local wind modification factors.\n",
    "\n",
    "As always, start with importing the required modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"C:/WorkSpace/data/raw/fiji_vector/fiji_vector.shp\"\n",
    "gdf = gpd.read_file(inputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first few lines to see what the file contains. It's a fairly simple file, with only four fields, plus the `geometry` field that `GeoPandas` adds to hold the geometry of the polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so it looks like the classification of the land cover is in the `CLASS_NAME` field. We use the `DataFrame.unique()` method to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverTypes = gdf['CLASS_NAME'].unique()\n",
    "print(coverTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Is there anything in the `SUB_CLASS` field? Now we need to see what the unique values are in this field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subTypes = gdf['SUB_CLASS'].unique()\n",
    "print(subTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes there is. So we need to handle the case of different combinations of `CLASS_NAME` and `SUB_CLASS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[['CLASS_NAME', 'SUB_CLASS']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_groups = gdf[['CLASS_NAME', 'SUB_CLASS']].drop_duplicates()\n",
    "classes = unique_groups.to_dict('split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to assign a numeric value to each class, which will then be inserted into a new field in the shape file. At a later point, we can assign the required roughness values to each class. \n",
    "\n",
    "Here we list out all the unique combinations of `CLASS_NAME` and `SUB_CLASS` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = dict()\n",
    "for i, t in enumerate(classes['data']):\n",
    "    key = (t[0], t[1])\n",
    "    classification[key] = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to insert the new field into the `GeoDataFrame`. First create a list containing the new numeric category for each row of the `GeoDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newclass = []\n",
    "for i, r in gdf.iterrows():\n",
    "    newclass.append(classification[(r.CLASS_NAME, r.SUB_CLASS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add the new `category` field to the `GeoDataFrame`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['category'] = np.asarray(newclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[['CLASS_NAME', 'SUB_CLASS', 'category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the updated `GeoDataFrame` back to a shapefile. If we really wanted, we could convert the coordinate reference system to a projected system for Fiji (e.g. EPSG:32760, i.e. UTM Zone 60S) using the `to_crs` method, then write the file.\n",
    "\n",
    "(This also solves a bit of an issue in displaying the data in GIS applications, where Fiji straddles the dateline.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfb = gdf.copy()\n",
    "gdfb = gdfb.to_crs({'init': 'epsg:32760'})\n",
    "gdfb.to_file(\"C:/WorkSpace/data/raw/fiji_vector/fiji_vectorprj.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use [`gdal_rasterize`](http://www.gdal.org/gdal_rasterize.html) to convert the shapefile into a raster for use in the wind multiplier calculation:\n",
    "\n",
    "    gdal_rasterize -a category -tr 25.0 25.0 -l fiji_vectorprj -ot Int32 fiji_vectorprj.shp landcoverprj.tif\n",
    "\n",
    "Just to have a cursory look a the data, we plot the count of all features in each of the categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,12))\n",
    "sns.countplot(x='CLASS_NAME',  data=gdf, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_xlabel(\"Land cover class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really should do is look at the area of each category. We can calculate the area of each category, by first transforming the coordinate reference system of the `GeoDataFrame` to an equal area CRS, using the `to_crs` method. \n",
    "\n",
    "We then calculate the total area in each class, by grouping first by the `CLASS_NAME` field, then summing over each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfa = gdf.copy()\n",
    "gdfa= gdfa.to_crs({'init': 'epsg:3395'})\n",
    "gdfa[\"area\"] = gdfa['geometry'].area/ 10**6\n",
    "\n",
    "areasum = gdfa.groupby(['CLASS_NAME', ])['area'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot a simple bar chart of the area (in km$^2$) of each class of land cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "areasum.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel(r\"Area (km$^2$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out the categories \n",
    "\n",
    "Finally, so we can use this data in the wind multiplier code, we need to prepare a CSV file with the category description and value. We will manually edit the CSV to add in an estimated roughness length for each category at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdf = gdf[['CLASS_NAME', 'SUB_CLASS', 'category']].drop_duplicates()\n",
    "catdf['Description'] = catdf['CLASS_NAME'] + '-' + catdf['SUB_CLASS'].fillna(\"None\")\n",
    "header = ['category', 'Description']\n",
    "catdf.to_csv(\"C:/WorkSpace/data/raw/fiji_vector/fiji_vector2.csv\", columns=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfb = gdf.copy()\n",
    "gdfb = gdfb.to_crs({'init': 'epsg:32760'})\n",
    "gdfb.to_file(\"C:/WorkSpace/data/raw/fiji_vector/fiji_vectorprj.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
