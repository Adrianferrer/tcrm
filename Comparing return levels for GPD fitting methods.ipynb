{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook requires Python 3.6*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing return level wind speeds for different GPD fitting methods\n",
    "\n",
    "To make full use of the scenarios generated in TCRM, it is preferred to use a Generalised Pareto Distribution (GPD) to fit the extremes of the distribution of simulated wind speeds. This utilises the peaks-over-threshold (POT) approach, rather than the block maxima (BM) approach used for the Generalised Extreme Value (GEV) distribution.\n",
    "\n",
    "The Generalised Pareto Distribution (GPD) is defined as:\n",
    "\n",
    "$H(y) = 1 - (1 + \\xi y / \\check{s}) ^{-1/\\xi}$\n",
    "\n",
    "where $\\check{s} = \\sigma + \\xi(u - \\mu)$ and $u = $ threshold value. $\\sigma$ and $\\mu$ are the scale and location parameters of a corresponding GEV distribution. If the data can be fitted to a GEV distribution, then values above the threshold can be fitted with a GPD.\n",
    "\n",
    "The fit of the GPD is highly sensitive to the selected threshold in POT methods. Too low a threshold and the fit is biased towards the bulk distribution at lower values. Too high a threshold and there are too few data points to provide a stable fit. Further to this, we want to select a threshold that results in a GPD with a negative shape parameter so that the resulting return levels are bounded. \n",
    "\n",
    "Here, we have precalculated the parameters for a GPD from the simulated TC wind speeds at a large number of locations across Australia. We used the iterative threshold selection method described by Sanabria and Cechet (2007), and a maximum likelihood estimation method, implemented in the `scipy.stats` package, using an arbitrary threshold (in our case, the 99.5th percentile of the simulated wind speeds at the site). We compare the return levels using these two methods, with a view to implementing one or the other in the TCRM code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with loading the data. This includes the return levels calculated using the iterative threshold selection and the percentile threshold selection, and the distribution parameters for each method. You can use the [tcrmextremes.py](https://github.com/wcarthur/extremes/blob/python/tcrmextremes.py) script to build these data files. This relies on a completed simulation of TCRM for the region you are investigating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"C:/WorkSpace/data/derived/tc/tcha/\"\n",
    "iterative_rl_file = pjoin(inputPath, \"iterative_rl.csv\")\n",
    "fitted_rl_file = pjoin(inputPath, \"fitted_rl.csv\")\n",
    "parameter_file = pjoin(inputPath, \"parameters.csv\")\n",
    "names = ['locId', 'locName', '1', '2', '5', '10', '20', '50',\n",
    "         '100', '200', '500', '1000', '2000', '5000', '10000']\n",
    "usecols = ['locId', '1', '2', '5', '10', '20', '50', '100',\n",
    "           '200', '500', '1000', '2000', '5000', '10000']\n",
    "\n",
    "it = pd.read_csv(iterative_rl_file, names=names, index_col='locId',\n",
    "                 usecols=usecols, header=0)\n",
    "ft = pd.read_csv(fitted_rl_file, names=names, index_col='locId',\n",
    "                 usecols=usecols, header=0)\n",
    "\n",
    "paramnames = ['locId', 'locName', 'it_scale', 'it_shape', 'it_thresh', 'it_rate',\n",
    "              'gpd_rate', 'gpd_shape', 'gpd_thresh', 'gpd_scale']\n",
    "usecols = ['locId', 'locName', 'it_scale', 'it_shape', 'it_thresh', 'it_rate',\n",
    "           'gpd_rate', 'gpd_shape', 'gpd_thresh', 'gpd_scale']\n",
    "params = pd.read_csv(parameter_file, names=paramnames, index_col='locId', usecols=usecols, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params[~params.duplicated()]\n",
    "it = it[~it.index.duplicated()]\n",
    "ft = ft[~ft.index.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to filter the data, to remove those records with an undefined shape parameter, a threshold of zero (which indicates a location with very few data points), and positive return level values for all return periods. This ensures the statistics we inspect are not influenced by questionable data. The replacement of invalid values is performed in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = params.where((params['it_shape'] !=0.0 ) & (params['gpd_shape'] != 0.0) &\\\n",
    "                   (params['gpd_thresh'] != 0.0) & (ft['1'] > 0.0) & (it['1'] > 0.0))\n",
    "flag = idx['it_shape'].isnull()\n",
    "it.loc[flag] = np.nan\n",
    "ft.loc[flag] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the difference between the two data frames. The resulting values are positive where the iterative selection method gives higher return levels, and negative where the percentile selection method gives higher return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = it.rsub(ft, axis=0)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot these data in a simple box plot to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.plot.box(title=\"Difference in return level wind speeds (n={0})\".format(diff[\"1\"].notnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with 319 valid sites, the mean difference between the two methods is at most 2.8 m/s. For the return periods that we are interested in for extreme events (> 50 years), the mean difference between the two methods is no more than 1 m/s. \n",
    "\n",
    "In terms of computing return levels quickly, the percentile threshold selection method is far superior. Given the computational efficiency, and the minimal differences in return levels (especially at long return periods), the percentile threshold selection method is being implemented into TCRM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rls = list(diff.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as feature\n",
    "import cartopy.io\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationFilePath = \"C:/WorkSpace/data/derived/tcobs/merged.shp\"\n",
    "locdf = gpd.read_file(locationFilePath)\n",
    "locdf = locdf.set_index([\"locId\"])\n",
    "locdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joindf = pd.merge(locdf, diff, left_index=True, right_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = joindf[joindf['1'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax.add_feature(feature.BORDERS)\n",
    "cs = ax.scatter(x=finaldf['Longitude'], y=finaldf['Latitude'], c=finaldf['100'], s=50,\n",
    "           cmap=sns.diverging_palette(240, 10, n=9, center='light', as_cmap=True))\n",
    "gl = ax.gridlines(linestyle=\":\",color='k', draw_labels=True)\n",
    "plt.colorbar(cs, orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReturnLevelDiff(rl, ):\n",
    "    df = diff.dropna([rl])\n",
    "    for locId in diff.index.values:\n",
    "        if diff.loc[locId][rl]:\n",
    "            output.append()\n",
    "        print(diff.loc[locId][rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diff[diff[\"1\"].notnull()]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
